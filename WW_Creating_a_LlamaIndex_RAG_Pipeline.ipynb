{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5TTdyIoo3i7"
      },
      "source": [
        "# Creating a LlamaIndex RAG Pipeline with NL2SQL and Metadata Filtering!\n",
        "\n",
        "We'll be putting together a system for querying both qualitative and quantitative data using LlamaIndex.\n",
        "\n",
        "The acitvities will be broken down as follows:\n",
        "\n",
        "- 🤝 Breakout Room #1\n",
        "  - Task 1: Load Dependencies\n",
        "  - Task 2: Set Env Variables and Set Up WandB Callback\n",
        "  - Task 3: Initialize Settings\n",
        "  - Task 4: Semantic RAG Pipeline with Metadata Filtering\n",
        "- 🤝 Breakout Room #2\n",
        "  - Task 1: Quantitative RAG Pipeline with NL2SQL Tooling\n",
        "  - Task 2: Combined RAG Pipeline\n",
        "\n",
        "Before we get started, however, a quick note on terminology.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcvGuykZSV_8"
      },
      "source": [
        "### A note on terminology:\n",
        "\n",
        "You'll notice that there are quite a few similarities between LangChain and LlamaIndex. LlamaIndex can largely be thought of as an extension to LangChain, in some ways - but they moved some of the language around. Let's spend a few moments disambiguating the language.\n",
        "\n",
        "- `QueryEngine` -> `LCEL Chain`:\n",
        "  -  `QueryEngine` is just LlamaIndex's way of indicating something is an LLM \"chain\" on top of a retrieval system\n",
        "- `OpenAIAgent` vs. `Agent`:\n",
        "  - The two agents have the same fundamental pattern: Decide which of a list of tools to use to answer a user's query.\n",
        "  - `OpenAIAgent` (LlamaIndex's primary agent) does not need to rely on an agent excecutor due to the fact that it is leveraging OpenAI's [functional api](https://openai.com/blog/function-calling-and-other-api-updates) which allows the agent to interface \"directly\" with the tools instead of operating through an intermediary application process.\n",
        "\n",
        "There is, however, a much large terminological difference when it comes to discussing data.\n",
        "\n",
        "##### Nodes vs. Documents\n",
        "\n",
        "As you're aware of from the previous weeks assignments, there's an idea of `documents` in NLP which refers to text objects that exist within a corpus of documents.\n",
        "\n",
        "LlamaIndex takes this a step further and reclassifies `documents` as `nodes`. Confusingly, it refers to the `Source Document` as simply `Documents`.\n",
        "\n",
        "The `Document` -> `node` structure is, almost exactly, equivalent to the `Source Document` -> `Document` structure found in LangChain - but the new terminology comes with some clarity about different structure-indices.\n",
        "\n",
        "We won't be leveraging those structured indicies today, but we will be leveraging a \"benefit\" of the `node` structure that exists as a default in LlamaIndex, which is the ability to quickly filter nodes based on their metadata.\n",
        "\n",
        "![image](https://i.imgur.com/B1QDjs5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkLLmDFnOfOs"
      },
      "source": [
        "# 🤝 Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msvju70DSV_8"
      },
      "source": [
        "## BOILERPLATE\n",
        "\n",
        "This is only relevant when running the code in a Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "7VF57GcmSV_9"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zQBPs6zSV_9"
      },
      "source": [
        "## Task 1: Load Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhEbxl3nSV_9"
      },
      "source": [
        "Let's grab our core `llama-index` library, as well as OpenAI's Python SDK.\n",
        "\n",
        "We'll be leveraging OpenAI's suite of APIs to power our RAG pipelines today.\n",
        "\n",
        "> NOTE: You can safely ignore any pip errors that occur during the running of these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3oyvtl2SV_9",
        "outputId": "41ef9ab4-5cb6-4094-b9aa-99eeb78378fd"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU llama-index openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jifl-qHO8MU"
      },
      "source": [
        "We'll be using [Weights and Biases](https://docs.wandb.ai/guides/prompts) (WandB) again for today's notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UcQpjG9Ovlk",
        "outputId": "b3e91a48-4b52-4c10-c0e7-30b7c3b4bd97"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU wandb llama-index-callbacks-wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqTXRTrLPatl"
      },
      "source": [
        "We'll be collecting our semantic data from Wikipedia - and so will need the [Wikipedia Reader](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/readers/llama-index-readers-wikipedia)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9kXf7pPSV_-",
        "outputId": "ea5f9d33-0448-4ecc-9814-ad0e42b867cc"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU wikipedia llama-index-readers-wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq_rWHZEPrCO"
      },
      "source": [
        "Our vector database today will be powered by [ChromaDB](https://github.com/chroma-core/chroma) and so we'll need that package as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iMCA8HFGEPF_"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU chromadb llama-index-vector-stores-chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNHDqna1P1NQ"
      },
      "source": [
        "Finally, we'll need to grab a few dependencies related to our quantitative data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrT8a3c0SV__",
        "outputId": "8d4e55c9-158f-4ce5-8308-11da18072bec"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -U sqlalchemy pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuZM6UjePVBk"
      },
      "source": [
        "We'll grab some additional miscellaneous dependencies here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqPJv3jUSV_-",
        "outputId": "b3386786-8dc0-45a8-e1ef-b2affe6a1315"
      },
      "outputs": [],
      "source": [
        "# !pip install -U -q tiktoken==0.4.0 sentence-transformers==2.2.2 pydantic==1.10.11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibtguieHP6n1"
      },
      "source": [
        "## Task 2: Set Env Variables and Set Up WandB Callback\n",
        "\n",
        "Let's set our API keys for both OpenAI and WandB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IBgMTPTSV_9",
        "outputId": "8d41d7f0-49ff-4bb4-daa1-acd3a99033ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OHSwkDySV_-",
        "outputId": "78455f0d-783c-4adb-e19a-af6a010cdf8e"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"WandB API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8E447rQBjY"
      },
      "source": [
        "We'll also need to set a callback handler for WandB to ensure smooth operation of our traces!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "MoV2JINuSV_-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LlamaIndex events to W&B at https://wandb.ai/ai-learners_bigk/aie1-llama-index-demo/runs/ojpu2jmk\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbCallbackHandler` is currently in beta.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
          ]
        }
      ],
      "source": [
        "import llama_index\n",
        "from llama_index.core import set_global_handler\n",
        "\n",
        "set_global_handler(\"wandb\", run_args={\"project\": \"aie1-llama-index-demo\"})\n",
        "wandb_callback = llama_index.core.global_handler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQwigweOSV_-"
      },
      "source": [
        "### Task 3: Settings\n",
        "\n",
        "LlamaIndex lets us set global settings which we can use to influence the default behaviour of our components.\n",
        "\n",
        "Let's set our LLM and our Embedding Model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "6KOy21KPSV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOdw7EQSV_-"
      },
      "source": [
        "## Task 4: Semantic RAG Pipeline with Metadata Filtering\n",
        "\n",
        "Now we can get to work creating our semantic `QueryEngine`!\n",
        "\n",
        "We'll start, as we normally do, by grabbing some data.\n",
        "\n",
        "> NOTE: Remember that a query engine is just a different word for a chain!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDEtQQWnSV_-"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We're just going to be pulling information straight from Wikipedia using the built in `WikipediaReader`.\n",
        "\n",
        "> NOTE: Setting `auto_suggest=False` ensures we run into fewer auto-correct based errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "OrzzrnYMSV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "\n",
        "movie_list = [\"Dune (2021 film)\", \"Dune: Part Two\"]\n",
        "\n",
        "wiki_docs = WikipediaReader().load_data(pages=movie_list, auto_suggest=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6FRQ4hfSV_-"
      },
      "source": [
        "### Initializing our VectorStoreIndex with ChromaDB\n",
        "\n",
        "ChromaDB is a locally hostable and open-source vector database solution.\n",
        "\n",
        "It offers powerful features like metadata filtering out of the box, and will suit our needs well today!\n",
        "\n",
        "We'll start by creating our local `EphemeralClient()` (in-memory and not meant for production use-cases) and our collection.\n",
        "\n",
        "Then we'll create our `VectorStore` and `StorageContext` which will allow us to create an empty `VectorStoreIndex` which we will be able to add nodes to later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "b1ut96aSEVwY"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import chromadb\n",
        "\n",
        "chroma_client = chromadb.EphemeralClient()\n",
        "# chroma_collection = chroma_client.create_collection(\"dune-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ5xilm1SV_-",
        "outputId": "3e0c322c-e0a5-4867-ae01-e5bcf77bef90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents([], storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qtzVDelSV_-"
      },
      "source": [
        "### Node Construction\n",
        "\n",
        "Now we will loop through our documents and metadata and construct nodes.\n",
        "\n",
        "We'll make sure to explicitly associate our nodes with their respective movie so we can filter by the movie title in the upcoming cells.\n",
        "\n",
        "> NOTE: You can safely ignore any WARNINGs in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP4INgSGSV_-",
        "outputId": "c0680135-0c2e-40b6-978f-97804a39d707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "Add of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "Add of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "Add of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "Add of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "Add of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "Add of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "Add of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "Add of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "Add of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "Add of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "Add of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "Add of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "Add of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "Add of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "Add of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "Add of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "Add of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "Add of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "Add of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "Add of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "Add of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "Add of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "Add of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "Add of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "Add of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "Add of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "Add of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "Add of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "Add of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "Add of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "Add of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "Add of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "Add of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "Add of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "Add of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "Add of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "Add of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "Add of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "Add of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "Add of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "Add of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "Add of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "Add of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "Add of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "Add of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "Add of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "Add of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "Add of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "Add of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "Add of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "Add of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "Add of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "Add of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "Add of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "Add of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "Add of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "Add of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "Add of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "Add of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "Add of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "Add of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "Add of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "Add of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n",
            "Add of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n",
            "Add of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n",
            "Add of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "Insert of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "Insert of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "Insert of existing embedding ID: e64be5fb-7492-43fd-abab-0d0cc960a14f\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "Insert of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "Insert of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "Insert of existing embedding ID: 5ba3b232-e048-4a3a-b349-a40acf1840b8\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "Insert of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "Insert of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "Insert of existing embedding ID: 93c62f1b-ba57-4c0c-8015-56f40bc5453a\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "Insert of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "Insert of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "Insert of existing embedding ID: 9f7ba6ce-d6af-4c2f-a50d-1f4e75f637e5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "Insert of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "Insert of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "Insert of existing embedding ID: 2d742bcc-2c88-4df9-a919-eb6fca861ef7\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "Insert of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "Insert of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "Insert of existing embedding ID: a2e8b242-37e0-48a2-9e96-3dd036ade19e\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "Insert of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "Insert of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "Insert of existing embedding ID: 3388383b-a20a-4408-a38c-0816f590cb27\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "Insert of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "Insert of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "Insert of existing embedding ID: 8759aad2-dc52-417c-82dd-bae3790fb796\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "Insert of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "Insert of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "Insert of existing embedding ID: ff8badb6-1aac-45d7-9118-58c0ee04fd1a\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "Insert of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "Insert of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "Insert of existing embedding ID: d6c313ef-2a52-4963-bb9f-3d9359ebdd36\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "Insert of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "Insert of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "Insert of existing embedding ID: 6a448358-3d0a-40f1-aa8c-196bcbb2a963\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "Insert of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "Insert of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "Insert of existing embedding ID: b47daf24-8be6-4c4e-9eb9-7de97ee12011\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "Insert of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "Insert of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "Insert of existing embedding ID: 3c227ee5-1e16-4854-8e73-59c0c36cbe5d\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "Insert of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "Insert of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "Insert of existing embedding ID: 79dcb2f6-958b-4b6b-be5e-5799c86fb9ab\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "Insert of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "Insert of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "Insert of existing embedding ID: c29c44a6-612f-402d-84d0-fb9be228106b\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "Insert of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "Insert of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "Insert of existing embedding ID: 8f7c3acd-2e8c-4f91-9467-17cace459d1c\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "Insert of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "Insert of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "Insert of existing embedding ID: 033c7267-d283-4fce-907a-36df3589ded2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "Insert of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "Insert of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "Insert of existing embedding ID: 15a3f9da-41b8-47d1-aeeb-0d6d3f282b97\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "Insert of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "Insert of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "Insert of existing embedding ID: 67fe01d5-1c95-4e46-a174-3147574ab4e5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "Insert of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "Insert of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "Insert of existing embedding ID: 9a3bd735-b7a0-4aeb-84b0-0a6ea5279628\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "Insert of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "Insert of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "Insert of existing embedding ID: 05aec1e0-f7b0-4420-9b2a-dbce0f5959a8\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n",
            "Insert of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n",
            "Insert of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n",
            "Insert of existing embedding ID: 6435e343-e2c6-4f6b-8aca-26500ed77c79\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "from llama_index.core.extractors import TitleExtractor\n",
        "\n",
        "pipeline = IngestionPipeline(transformations=[TokenTextSplitter()])\n",
        "\n",
        "for movie, wiki_doc in zip(movie_list, wiki_docs):\n",
        "    nodes = pipeline.run(documents=wiki_docs)\n",
        "    for node in nodes:\n",
        "        node.metadata = {\"title\" : movie}\n",
        "    index.insert_nodes(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biVzC-I4UAmB"
      },
      "source": [
        "####❓ Question #1:\n",
        "\n",
        "What `metadata` fields will the nodes in our index have?\n",
        "\n",
        "Please write the code to find this information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "mt1lhxEnUKxO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'title': 'Dune: Part Two'}\n",
            "{'title': 'Dune: Part Two'}\n"
          ]
        }
      ],
      "source": [
        "# We only add titles as metadata\n",
        "print(node.metadata)\n",
        "print(nodes[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfbon1BwSLFS"
      },
      "source": [
        "### Persisting and Loading Stored Index with Weights and Biases\n",
        "\n",
        "Now we can utilize a powerful feature of Weights and Biases - index and artifact versioning!\n",
        "\n",
        "We can persist our index to WandB to be used and loaded later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJd00J3G48_",
        "outputId": "daead28f-68f4-4f98-b417-3552ad986839"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/william.wetzel/maven/AI-Engineering/week_4/day_2/wandb/run-20240309_192610-ojpu2jmk/files/storage)... Done. 0.0s\n"
          ]
        }
      ],
      "source": [
        "wandb_callback.persist_index(index, index_name=\"dune-index-chromadb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvpHLt8UShKa"
      },
      "source": [
        "Now we can load our index from WandB, which is a truly powerful tool!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDZLmqTDHDrZ",
        "outputId": "ade0c7d2-841e-4a50-e296-0f71b45dc1b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "storage_context = wandb_callback.load_storage_context(\n",
        "    artifact_url=\"ai-learners_bigk/aie1-llama-index-demo/dune-index-chromadb:v0\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0pwSiOxUYCE"
      },
      "source": [
        "####❓ Question #2:\n",
        "\n",
        "Provide a screenshot of your index version history as shown in WandB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![weee](./img10.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUa5sHMsSV__"
      },
      "source": [
        "### Auto Retriever Functional Tool\n",
        "\n",
        "This tool will leverage OpenAI's functional endpoint to select the correct metadata filter and query the filtered index - only looking at nodes with the desired metadata.\n",
        "\n",
        "A simplified diagram: ![image](https://i.imgur.com/AICDPav.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2HQHY3pSV__"
      },
      "source": [
        "First, we need to create our `VectoreStoreInfo` object which will hold all the relevant metadata we need for each component (in this case title metadata).\n",
        "\n",
        "Notice that you need to include it in a text list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "KoAYxbdsSV__"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.vector_stores.types import (\n",
        "    VectorStoreInfo,\n",
        "    MetadataInfo,\n",
        "    ExactMatchFilter,\n",
        "    MetadataFilters,\n",
        ")\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from typing import List, Tuple, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "top_k = 3\n",
        "\n",
        "vector_store_info = VectorStoreInfo(\n",
        "    content_info=\"semantic information about movies\",\n",
        "    metadata_info=[MetadataInfo(\n",
        "        name=\"title\",\n",
        "        type=\"str\",\n",
        "        description=\"title of the movie, one of ['Dune (2021 film)', 'Dune: Part 2']\",\n",
        "    )]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEjK7jcsSV__"
      },
      "source": [
        "Now we'll create our base PyDantic object that we can use to ensure compatability with our application layer. This verifies that the response from the OpenAI endpoint conforms to this schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "yixkwF8zSV__"
      },
      "outputs": [],
      "source": [
        "class AutoRetrieveModel(BaseModel):\n",
        "    query: str = Field(..., description=\"natural language query string\")\n",
        "    filter_key_list: List[str] = Field(\n",
        "        ..., description=\"List of metadata filter field names\"\n",
        "    )\n",
        "    filter_value_list: List[str] = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep6ORS3FSV__"
      },
      "source": [
        "Now we can build our function that we will use to query the functional endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "y8sPThxlSV__"
      },
      "outputs": [],
      "source": [
        "def auto_retrieve_fn(\n",
        "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
        "):\n",
        "    \"\"\"Auto retrieval function.\n",
        "\n",
        "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
        "\n",
        "    \"\"\"\n",
        "    query = query or \"Query\"\n",
        "\n",
        "    exact_match_filters = [\n",
        "        ExactMatchFilter(key=k, value=v)\n",
        "        for k, v in zip(filter_key_list, filter_value_list)\n",
        "    ]\n",
        "    retriever = VectorIndexRetriever(\n",
        "        index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
        "    )\n",
        "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
        "\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4BV6oISV__"
      },
      "source": [
        "Now we need to wrap our system in a tool in order to integrate it into the larger application.\n",
        "\n",
        "Source Code Here:\n",
        "- [`FunctionTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/function_tool.py#L21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "U4lS1NqeSV__"
      },
      "outputs": [],
      "source": [
        "description = f\"\"\"\\\n",
        "Use this tool to look up semantic information about films.\n",
        "The vector database schema is given below:\n",
        "{vector_store_info.json()}\n",
        "\"\"\"\n",
        "\n",
        "auto_retrieve_tool = FunctionTool.from_defaults(\n",
        "    fn=auto_retrieve_fn,\n",
        "    name=\"semantic-film-info\",\n",
        "    description=description,\n",
        "    fn_schema=AutoRetrieveModel\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YkXmlexUnP_"
      },
      "source": [
        "####❓ Question #3:\n",
        "\n",
        "Is the text in the description of our `FunctionTool` important or not? Please explain your answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Yes, the description helps the LLM decide which tool to use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZblimmXVSV__"
      },
      "source": [
        "All that's left to do is attach the tool to an OpenAIAgent and let it rip!\n",
        "\n",
        "Source Code Here:\n",
        "- [`OpenAIAgent`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/agent/openai_agent.py#L361)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "W2hafCTxSV__"
      },
      "outputs": [],
      "source": [
        "from llama_index.agent.openai import OpenAIAgent\n",
        "\n",
        "agent = OpenAIAgent.from_tools(\n",
        "    tools=[auto_retrieve_tool],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBJWDBK5SV__",
        "outputId": "89542691-c922-44cc-9663-90a372df4837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Who starred in the 2021 film?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\":\"cast of Dune (2021 film)\",\"filter_key_list\":[\"title\"],\"filter_value_list\":[\"Dune (2021 film)\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The cast of \"Dune\" (2021 film) includes Timothée Chalamet as Paul \"Muad'Dib\" Atreides, Zendaya as Chani, Rebecca Ferguson as Lady Jessica, Josh Brolin as Gurney Halleck, Austin Butler as Feyd-Rautha Harkonnen, Florence Pugh as Princess Irulan, Dave Bautista as Glossu Rabban Harkonnen, Christopher Walken as Shaddam IV, Léa Seydoux as Lady Margot Fenring, Souheila Yacoub as Shishakli, Stellan Skarsgård as Baron Vladimir Harkonnen, and Charlotte Rampling as Gaius Helen Mohiam.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cast of the 2021 film \"Dune\" includes Timothée Chalamet, Zendaya, Rebecca Ferguson, Josh Brolin, Austin Butler, Florence Pugh, Dave Bautista, Christopher Walken, Léa Seydoux, Souheila Yacoub, Stellan Skarsgård, and Charlotte Rampling.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Who starred in the 2021 film?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbhAT68RSvnT"
      },
      "source": [
        "# 🤝 Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJcJL7VXSV__"
      },
      "source": [
        "## Task 1: Quantitative RAG Pipeline with NL2SQL Tooling\n",
        "\n",
        "We'll walk through the steps of creating a natural language to SQL system in the following section.\n",
        "\n",
        "> NOTICE: This does not have parsing on the inputs or intermediary calls to ensure that users are using safe SQL queries. Use this with caution in a production environment without adding specific guardrails from either side of the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsVcM0-4SV__"
      },
      "source": [
        "The next few steps should be largely straightforward, we'll want to:\n",
        "\n",
        "1. Read in our `.csv` files into `pd.DataFrame` objects\n",
        "2. Create an in-memory `sqlite` powered `sqlalchemy` engine\n",
        "3. Cast our `pd.DataFrame` objects to the SQL engine\n",
        "4. Create an `SQLDatabase` object through LlamaIndex\n",
        "5. Use that to create a `QueryEngineTool` that we can interact with through the `NLSQLTableQueryEngine`!\n",
        "\n",
        "If you get stuck, please consult the documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwWOygTqlNBh",
        "outputId": "86b0a67f-3fc0-45ae-8afe-889d85903ef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-09 19:04:42--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 OK\n",
            "Length: 133391 (130K) [text/plain]\n",
            "Saving to: ‘dune1.csv.1’\n",
            "\n",
            "dune1.csv.1         100%[===================>] 130.26K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-03-09 19:04:42 (6.20 MB/s) - ‘dune1.csv.1’ saved [133391/133391]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD_9LPL9lTlG",
        "outputId": "b99f4c30-ae9b-4323-a102-9d4f39c36f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-09 19:04:42--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 OK\n",
            "Length: 111843 (109K) [text/plain]\n",
            "Saving to: ‘dune2.csv.1’\n",
            "\n",
            "dune2.csv.1         100%[===================>] 109.22K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-03-09 19:04:42 (5.48 MB/s) - ‘dune2.csv.1’ saved [111843/111843]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune2.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PUg-ZuTSWAC"
      },
      "source": [
        "#### Read `.csv` Into Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "52Hd8PM4SWAC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dune1_df = pd.read_csv(\"./dune1.csv\")\n",
        "dune2_df = pd.read_csv(\"./dune2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPTNyqmpSWAC"
      },
      "source": [
        "#### Create SQLAlchemy engine with SQLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4lfuPKYBSWAC"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"sqlite+pysqlite:///:memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJiYiSuHSWAC"
      },
      "source": [
        "#### Convert `pd.DataFrame` to SQL tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-96asUHSWAC",
        "outputId": "237d5720-fb5c-42b0-b5c8-a9a9023eeb80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dune1_df.to_sql(\n",
        "    \"Dune (2021 film)\",\n",
        "    engine\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwOi1RE1SWAC",
        "outputId": "86bd0057-3086-4af5-db71-d8d7e1e64be1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dune2_df.to_sql(\n",
        "    \"Dune: Part 2\",\n",
        "    engine\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pibA9qT7SWAC"
      },
      "source": [
        "#### Construct a `SQLDatabase` index\n",
        "\n",
        "Source Code Here:\n",
        "- [`SQLDatabase`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/langchain_helpers/sql_wrapper.py#L9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "yeDYpR1LSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SQLDatabase\n",
        "\n",
        "sql_database = SQLDatabase(\n",
        "    engine=engine,\n",
        "    include_tables=[\"Dune (2021 film)\", \"Dune: Part 2\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7VfZBenSWAD"
      },
      "source": [
        "#### Create the NLSQLTableQueryEngine interface for all added SQL tables\n",
        "\n",
        "Source Code Here:\n",
        "- [`NLSQLTableQueryEngine`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/indices/struct_store/sql_query.py#L75C1-L75C1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "zQWSdMtrSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
        "\n",
        "sql_query_engine = NLSQLTableQueryEngine(\n",
        "    sql_database=sql_database,\n",
        "    tables=[\"Dune (2021 film)\", \"Dune: Part 2\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu8WfwuTSWAD"
      },
      "source": [
        "#### Wrap It All Up in a `QueryEngineTool`\n",
        "\n",
        "You'll want to ensure you have a descriptive...description.\n",
        "\n",
        "An example is provided here:\n",
        "\n",
        "```\n",
        "Useful for translating a natural language query into a SQL query over a table containing:\n",
        "John Wick 1, containing information related to reviews of the first John Wick movie, called John Wick\n",
        "John Wick 2, containing information related to reviews of the second John Wick movie, called John Wick: Chapter 2\n",
        "John Wick 3, containing information related to reviews of the third John Wick movie, called John Wick: Chatper 3 - Parabellum\n",
        "John Wick 4, containing information related to reviews of the fourth John Wick movie, called John Wick: Chatper 4\n",
        "```\n",
        "\n",
        "Sorce Code Here:\n",
        "\n",
        "- [`QueryEngineTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/query_engine.py#L13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDB2m2dnU54L"
      },
      "source": [
        "####🏗️ Activity #1:\n",
        "\n",
        "Please write a Natural Language Description for the tables that we are using today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "4n567cXVVCtX"
      },
      "outputs": [],
      "source": [
        "DESCRIPTION = \"\"\"\n",
        "Useful for translating a natural language query into a SQL query over a table containing:\n",
        "Dune (2021 file), containing information related to reviews of the first Dune movie, called Dune (2021 film)\n",
        "Dune: Part 2, containing information related to reviews of the second Dune movie, called Dune: Part 2\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "y-mmcBbLSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools.query_engine import QueryEngineTool\n",
        "\n",
        "sql_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=sql_query_engine,\n",
        "    name=\"sql-query\",\n",
        "    description=DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "feOrlq4XSWAD"
      },
      "outputs": [],
      "source": [
        "agent = OpenAIAgent.from_tools(\n",
        "    tools=[sql_tool],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "iT4G6stBSWAD",
        "outputId": "fc90e9c7-2484-4a6b-c274-cd9407b4fa6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is the average rating of the 2nd Dune movie?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\":\"SELECT AVG(rating) FROM 'Dune: Part 2'\"}\n",
            "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The average rating for 'Dune: Part 2' is approximately 8.71.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What is the average rating of the 2nd Dune movie?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhsoxOpkSWAD",
        "outputId": "804386f4-b3d1-4c22-dd72-1fd047a6a5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average rating for the 2nd Dune movie, \"Dune: Part 2,\" is approximately 8.71.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2LOixbcSWAD"
      },
      "source": [
        "### Task 2: Combined RAG Pipeline\n",
        "\n",
        "Now, we can simply add our tools into the `OpenAIAgent`, and off we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "uxFHM2l2SWAD"
      },
      "outputs": [],
      "source": [
        "dune_agent = OpenAIAgent.from_tools(\n",
        "    tools=[auto_retrieve_tool, sql_tool],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYVHuBf9SWAD",
        "outputId": "e3f77503-302e-491e-9d1d-e2e7d4d9f6ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is the lowest rating of the 1st film?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\":\"lowest rating of the 1st film\",\"filter_key_list\":[\"title\"],\"filter_value_list\":[\"Dune (2021 film)\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The lowest rating of the 1st film was an average grade of \"A−\" on an A+ to F scale by audiences polled by CinemaScore.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = dune_agent.chat(\"What is the lowest rating of the 1st film?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0w0VbomSWAD",
        "outputId": "df61ee6d-8843-4f92-df84-29111890b123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The lowest rating of the 1st film, \"Dune (2021 film),\" was an average grade of \"A−\" on an A+ to F scale by audiences polled by CinemaScore.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJvN-vtJSWAD",
        "outputId": "1485a111-0ecf-4544-993e-b48bcce7413a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What planet does the 1st Dune movie take place on?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\":\"planet where the 1st Dune movie takes place\",\"filter_key_list\":[\"title\"],\"filter_value_list\":[\"Dune (2021 film)\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: Arrakis\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = dune_agent.chat(\"What planet does the 1st Dune movie take place on?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F74wGv6NSWAD",
        "outputId": "3232efff-51e9-4b4e-a859-673d5a777598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 1st Dune movie, \"Dune (2021 film),\" takes place on the planet Arrakis.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvat4hmkvn3N",
        "outputId": "47406f60-dafb-4a23-9dea-541fc31a1f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Calculate the average review of each movie - and then discuss how the average review changed over time.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) AS average_rating FROM 'Dune (2021 film)'\"}\n",
            "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The average rating for the movie \"Dune (2021 film)\" is 8.34 out of 10.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"SELECT AVG(rating) AS average_rating FROM 'Dune: Part 2'\"}\n",
            "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part 2' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The average rating for 'Dune: Part 2' is 8.71.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = dune_agent.chat(\"Calculate the average review of each movie - and then discuss how the average review changed over time.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEOpeuAovtZM",
        "outputId": "08eb37ef-1fd6-47da-9e23-6c847c4d205c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average review for the movie \"Dune (2021 film)\" is 8.34 out of 10, and for \"Dune: Part 2\" is 8.71 out of 10.\n",
            "\n",
            "Over time, the average review of the Dune movies has shown an improvement from the first film to the second. The increase in the average rating from 8.34 to 8.71 indicates that audiences generally found the second movie, \"Dune: Part 2,\" to be even more positively received than the first film. This suggests that the sequel was able to build upon the success and appeal of the original movie, leading to a higher average rating.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUVzyUtKqdUf"
      },
      "source": [
        "####❓ Question #4:\n",
        "\n",
        "How can you verify which tool was used for which query?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sql-query\n",
            "sql-query\n"
          ]
        }
      ],
      "source": [
        "print(response.sources[0].tool_name)\n",
        "print(response.sources[1].tool_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "llama_index.core.tools.types.ToolOutput"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(response.sources[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AgentChatResponse(response='The average review rating for the movie \"Dune (2021 film)\" is 8.34 out of 10, while the average review score for \"Dune: Part 2\" is approximately 11.59 out of 10.\\n\\nOver time, the average review of the Dune movies has increased significantly from the first film to the second. This indicates that the second movie, \"Dune: Part 2,\" received a higher average review score compared to the first film, \"Dune (2021 film).\" The improvement in the average review score suggests that the second movie was potentially more well-received by audiences and critics, leading to a positive trend in the overall reception of the Dune series.', sources=[ToolOutput(content='The average review rating for the movie \"Dune (2021 film)\" is 8.34 out of 10.', tool_name='sql-query', raw_input={'input': \"SELECT AVG(review) AS average_review FROM 'Dune (2021 film)'\"}, raw_output=Response(response='The average review rating for the movie \"Dune (2021 film)\" is 8.34 out of 10.', source_nodes=[NodeWithScore(node=TextNode(id_='84baa253-950a-46f1-835e-17c8c9e6d605', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[(8.335793357933579,)]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)], metadata={'84baa253-950a-46f1-835e-17c8c9e6d605': {}, 'sql_query': \"SELECT AVG(Rating) AS average_review FROM 'Dune (2021 film)'\", 'result': [(8.335793357933579,)], 'col_keys': ['average_review']})), ToolOutput(content=\"The average review score for 'Dune: Part 2' is approximately 11.59.\", tool_name='sql-query', raw_input={'input': \"SELECT AVG(review) AS average_review FROM 'Dune: Part 2'\"}, raw_output=Response(response=\"The average review score for 'Dune: Part 2' is approximately 11.59.\", source_nodes=[NodeWithScore(node=TextNode(id_='658faee8-f35d-4062-8203-8f149ccedb30', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[(11.588571428571429,)]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)], metadata={'658faee8-f35d-4062-8203-8f149ccedb30': {}, 'sql_query': \"SELECT AVG(Review) AS average_review FROM 'Dune: Part 2'\", 'result': [(11.588571428571429,)], 'col_keys': ['average_review']}))], source_nodes=[NodeWithScore(node=TextNode(id_='84baa253-950a-46f1-835e-17c8c9e6d605', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[(8.335793357933579,)]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None), NodeWithScore(node=TextNode(id_='658faee8-f35d-4062-8203-8f149ccedb30', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='[(11.588571428571429,)]', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=None)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "D3ELqzOvSWAD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
          ]
        }
      ],
      "source": [
        "wandb_callback.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
